{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac226ab7-c79b-4eb6-b369-9e000f9dc731",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Assuming X is your feature DataFrame and y is your target\u001b[39;00m\n\u001b[1;32m     12\u001b[0m label_encoders \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X[column]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     15\u001b[0m         le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Adult dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', \n",
    "                'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv(url, names=column_names, skipinitialspace=True, na_values='?')\n",
    "\n",
    "# Assuming X is feature DataFrame and y is target\n",
    "label_encoders = {}\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        X[column] = le.fit_transform(X[column])\n",
    "        label_encoders[column] = le\n",
    "\n",
    "# Preprocess the data\n",
    "df = df.dropna()\n",
    "df['income'] = df['income'].map({'>50K': 1, '<=50K': 0})\n",
    "sensitive_attribute = 'sex'\n",
    "label = 'income'\n",
    "\n",
    "# Split the data\n",
    "X = df.drop('income', axis=1)\n",
    "y = df['income']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c95f0bbe-6c7c-4082-bf6a-b431556fa14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.11.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.4.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (4.11.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.16.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.65.5-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow)\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Collecting rich (from keras>=3.2.0->tensorflow)\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow)\n",
      "  Using cached optree-0.12.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.2.0->tensorflow)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from rich->keras>=3.2.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.18,>=2.17->tensorflow) (3.17.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.17.0-cp39-cp39-macosx_12_0_arm64.whl (236.1 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.65.5-cp39-cp39-macosx_10_9_universal2.whl (10.5 MB)\n",
      "Using cached h5py-3.11.0-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Using cached ml_dtypes-0.4.0-cp39-cp39-macosx_10_9_universal2.whl (390 kB)\n",
      "Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Using cached protobuf-4.25.4-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-macosx_12_0_arm64.whl (3.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached wrapt-1.16.0-cp39-cp39-macosx_11_0_arm64.whl (38 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp39-cp39-macosx_11_0_arm64.whl (282 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, h5py, grpcio, google-pasta, gast, astunparse, absl-py, markdown-it-py, markdown, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.65.5 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.0 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.4 rich-13.7.1 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-2.4.0 werkzeug-3.0.3 wrapt-1.16.0\n",
      "Collecting fairlearn\n",
      "  Using cached fairlearn-0.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from fairlearn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.0.3 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from fairlearn) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from fairlearn) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from fairlearn) (1.13.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=2.0.3->fairlearn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=2.0.3->fairlearn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=2.0.3->fairlearn) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from scikit-learn>=1.2.1->fairlearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from scikit-learn>=1.2.1->fairlearn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.3->fairlearn) (1.16.0)\n",
      "Using cached fairlearn-0.10.0-py3-none-any.whl (234 kB)\n",
      "Installing collected packages: fairlearn\n",
      "Successfully installed fairlearn-0.10.0\n",
      "Collecting inFairness\n",
      "  Using cached inFairness-0.2.3-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from inFairness) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.3.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from inFairness) (2.2.2)\n",
      "Collecting POT>=0.8.0 (from inFairness)\n",
      "  Using cached POT-0.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.24.2 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from inFairness) (1.5.1)\n",
      "Requirement already satisfied: scipy>=1.5.4 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from inFairness) (1.13.1)\n",
      "Collecting torch>=1.13.0 (from inFairness)\n",
      "  Using cached torch-2.4.0-cp39-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=1.3.5->inFairness) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=1.3.5->inFairness) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from pandas>=1.3.5->inFairness) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from scikit-learn>=0.24.2->inFairness) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from scikit-learn>=0.24.2->inFairness) (3.5.0)\n",
      "Collecting filelock (from torch>=1.13.0->inFairness)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from torch>=1.13.0->inFairness) (4.11.0)\n",
      "Collecting sympy (from torch>=1.13.0->inFairness)\n",
      "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.13.0->inFairness)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from torch>=1.13.0->inFairness) (3.1.4)\n",
      "Collecting fsspec (from torch>=1.13.0->inFairness)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->inFairness) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ttanaka/miniconda3/envs/new_env_name/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->inFairness) (2.1.3)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.13.0->inFairness)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached inFairness-0.2.3-py3-none-any.whl (45 kB)\n",
      "Using cached POT-0.9.4-cp39-cp39-macosx_11_0_arm64.whl (305 kB)\n",
      "Using cached torch-2.4.0-cp39-none-macosx_11_0_arm64.whl (62.1 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, POT, inFairness\n",
      "Successfully installed POT-0.9.4 filelock-3.15.4 fsspec-2024.6.1 inFairness-0.2.3 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.2 torch-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install fairlearn\n",
    "!pip install inFairness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d471aa6-d6b8-4769-86d6-9ad1b57fbd39",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Apply LabelEncoder to each categorical column\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[43mX_train\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m      8\u001b[0m     X_train[column] \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mfit_transform(X_train[column])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to each categorical column\n",
    "for column in X_train.select_dtypes(include=['object']).columns:\n",
    "    X_train[column] = le.fit_transform(X_train[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42216273-35c9-4dc4-a880-394f5ef28a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact before mitigation: 0.3647382591137069\n"
     ]
    }
   ],
   "source": [
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "\n",
    "# Assuming `income` is your label and `sensitive_attribute` is defined\n",
    "train_data = BinaryLabelDataset(df=pd.concat([X_train, y_train], axis=1), \n",
    "                                label_names=['income'], \n",
    "                                protected_attribute_names=[sensitive_attribute])\n",
    "\n",
    "# Measure bias\n",
    "metric = BinaryLabelDatasetMetric(train_data, unprivileged_groups=[{sensitive_attribute: 0}], \n",
    "                                  privileged_groups=[{sensitive_attribute: 1}])\n",
    "print(f\"Disparate impact before mitigation: {metric.disparate_impact()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "948d1cb7-70de-450f-bb7e-e2a96727d36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disparate impact after mitigation: 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "\n",
    "# Apply bias mitigation technique (Reweighing)\n",
    "rw = Reweighing(unprivileged_groups=[{sensitive_attribute: 0}], \n",
    "                privileged_groups=[{sensitive_attribute: 1}])\n",
    "train_data_transformed = rw.fit_transform(train_data)\n",
    "\n",
    "# Measure bias after mitigation\n",
    "metric_transformed = BinaryLabelDatasetMetric(train_data_transformed, \n",
    "                                              unprivileged_groups=[{sensitive_attribute: 0}], \n",
    "                                              privileged_groups=[{sensitive_attribute: 1}])\n",
    "print(f\"Disparate impact after mitigation: {metric_transformed.disparate_impact()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e759d6de-e73c-46e2-9a66-f95e606476d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on original data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      4503\n",
      "           1       0.76      0.62      0.68      1530\n",
      "\n",
      "    accuracy                           0.85      6033\n",
      "   macro avg       0.82      0.78      0.79      6033\n",
      "weighted avg       0.85      0.85      0.85      6033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# X and y are features and target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify categorical columns in your dataset\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Create a preprocessing pipeline to handle categorical and numeric data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_columns),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Define a pipeline with preprocessing and the Logistic Regression model\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=5000))\n",
    "])\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    # Train the model\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "    \n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Original data\n",
    "print(\"Model performance on original data:\")\n",
    "train_and_evaluate(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# If you have transformed data, make sure it's split into train and test sets\n",
    "if 'train_data_transformed' in locals():\n",
    "    X_train_transformed = train_data_transformed.features\n",
    "    y_train_transformed = train_data_transformed.labels.ravel()\n",
    "    \n",
    "    # Convert numpy array to pandas DataFrame\n",
    "    if isinstance(X_train_transformed, np.ndarray):\n",
    "        X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674802e6-c492-48c5-aeb9-03ac56cdd2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on original data:\n",
      "\n",
      "Original Model Performance:\n",
      "Accuracy: 0.8122\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88      4503\n",
      "           1       0.73      0.41      0.52      1530\n",
      "\n",
      "    accuracy                           0.81      6033\n",
      "   macro avg       0.78      0.68      0.70      6033\n",
      "weighted avg       0.80      0.81      0.79      6033\n",
      "\n",
      "\n",
      "Evaluating on transformed (mitigated) data:\n",
      "\n",
      "Transformed Model Performance:\n",
      "Accuracy: 0.8230\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.89      4503\n",
      "         1.0       0.74      0.46      0.57      1530\n",
      "\n",
      "    accuracy                           0.82      6033\n",
      "   macro avg       0.79      0.70      0.73      6033\n",
      "weighted avg       0.81      0.82      0.81      6033\n",
      "\n",
      "\n",
      "Accuracy Comparison:\n",
      "Original Model Accuracy: 0.8122\n",
      "Transformed Model Accuracy: 0.8230\n",
      "Accuracy Difference (Transformed - Original): 0.0108\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def prepare_data(X):\n",
    "    # Identify categorical and numeric columns\n",
    "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "    numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Create preprocessing pipeline\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_columns),\n",
    "            ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
    "        ])\n",
    "\n",
    "    # Create model pipeline\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=5000))\n",
    "    ])\n",
    "    \n",
    "    return model_pipeline\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test, model_name=\"Model\"):\n",
    "    # Prepare the data and model\n",
    "    model = prepare_data(X_train)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model, accuracy\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(X):\n",
    "    categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].astype('category').cat.codes\n",
    "    return X\n",
    "\n",
    "# Preprocess original data\n",
    "X_train_preprocessed = preprocess_data(X_train)\n",
    "X_test_preprocessed = preprocess_data(X_test)\n",
    "\n",
    "# Evaluate on original data\n",
    "print(\"Evaluating on original data:\")\n",
    "original_model, original_accuracy = train_and_evaluate(X_train_preprocessed, X_test_preprocessed, y_train, y_test, \"Original Model\")\n",
    "\n",
    "# Apply bias mitigation to preprocessed data\n",
    "train_data_preprocessed = BinaryLabelDataset(df=pd.concat([X_train_preprocessed, y_train], axis=1), \n",
    "                                             label_names=['income'], \n",
    "                                             protected_attribute_names=[sensitive_attribute])\n",
    "\n",
    "rw = Reweighing(unprivileged_groups=[{sensitive_attribute: 0}], \n",
    "                privileged_groups=[{sensitive_attribute: 1}])\n",
    "train_data_transformed = rw.fit_transform(train_data_preprocessed)\n",
    "\n",
    "# Transform test data\n",
    "test_data_preprocessed = BinaryLabelDataset(df=pd.concat([X_test_preprocessed, y_test], axis=1), \n",
    "                                            label_names=['income'], \n",
    "                                            protected_attribute_names=[sensitive_attribute])\n",
    "test_data_transformed = rw.transform(test_data_preprocessed)\n",
    "\n",
    "# Prepare transformed data for evaluation\n",
    "X_train_transformed = pd.DataFrame(train_data_transformed.features, columns=X_train.columns)\n",
    "y_train_transformed = train_data_transformed.labels.ravel()\n",
    "X_test_transformed = pd.DataFrame(test_data_transformed.features, columns=X_test.columns)\n",
    "y_test_transformed = test_data_transformed.labels.ravel()\n",
    "\n",
    "# Evaluate on transformed data\n",
    "print(\"\\nEvaluating on transformed (mitigated) data:\")\n",
    "transformed_model, transformed_accuracy = train_and_evaluate(X_train_transformed, X_test_transformed, \n",
    "                                                             y_train_transformed, y_test_transformed, \n",
    "                                                             \"Transformed Model\")\n",
    "\n",
    "# Compare accuracies\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "print(f\"Original Model Accuracy: {original_accuracy:.4f}\")\n",
    "print(f\"Transformed Model Accuracy: {transformed_accuracy:.4f}\")\n",
    "print(f\"Accuracy Difference (Transformed - Original): {transformed_accuracy - original_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2b160-bcf0-4eca-b040-2d882aed5005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
